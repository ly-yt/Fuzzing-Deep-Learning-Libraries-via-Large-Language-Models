# Fuzzing-Deep-Learning-Libraries-via-Large-Language-Models
## å¯¹ä¸€ç¯‡è®ºæ–‡çš„å°è§„æ¨¡å¤ç° [è®ºæ–‡åœ°å€](https://arxiv.org/abs/2212.14834 "æ‚¬åœæ˜¾ç¤º")
### æ–¹æ³•å®ç°
---
#### ç”¨codexåˆå§‹ä»£ç ç§å­åº“ï¼ˆå…·ä½“ä»£ç å®ç°æŸ¥çœ‹codex.pyï¼‰
1. é€‰å–ä¸»æµæ·±åº¦å­¦ä¹ åº“â€”â€”`tensorflow`ï¼ˆç”±äºæœ¬ä»“åº“åªå®ç°å°è§„æ¨¡æ•°æ®å¤ç°ï¼Œæ•…åªé€‰å–tensorflowåº“çš„`æ ¸å¿ƒapiæ¥å£`è¿›è¡Œè‡ªåŠ¨åŒ–ä»£ç æµ‹è¯•ï¼‰
2. é€‰æ‹©çš„`æ ¸å¿ƒapiæ¥å£`ä¸»è¦æœ‰ä»¥ä¸‹ä¸‰ç±»ï¼š  
* åŸºæœ¬è¿ç®—ï¼štf.expand_dimsã€tf.splitã€tf.concatã€tf.castã€tf.reshapeã€tf.equalã€tf.matmulã€tf.argmaxã€tf.squeeze  
- æ­å»ºç½‘ç»œï¼štf.nn.conv2dã€tf.nn.max_poolã€tf.nn.avg_poolã€tf.nn.reluã€tf.nn.dropoutã€tf.nn.l2_normalizeã€tf.nn.batch_normalizationã€tf.nn.l2_lossã€tf.nn.softmax_cross_entropy_with_logits  
* è®­ç»ƒä¼˜åŒ–ï¼štf.train.Saverã€tf.train.Saver.restoreã€tf.train.GradientDescentOptimizer(0.01).minimize(loss)ã€tf.train.exponential_decay(learning_rate=1e-2, global_step=sample_size/batch, decay_rate=0.98, staircase=True)ã€tf.train.string_input_producer(string_tensor, num_epochs, shuffle=True)ã€tf.train.shuffle_batch(tensors=[example, label], batch_size, capacity, min_after_dequeue)ã€tf.train.Coordinator()ã€tf.train.start_queue_runners(sess, coord)   
3. è¾“å…¥æç¤ºè¯ï¼Œè·å¾—ä¸Šè¿°å„ä¸ªapiæ¥å£åº”ç”¨codexæ¨¡å‹è‡ªåŠ¨ç”Ÿæˆçš„çš„ä»£ç ç§å­åº“  
ä»¥ä¸‹é€‰å–tf.nnä½œä¸ºç›®æ ‡apiæ¥å£è¿›è¡Œå®ä¾‹å±•ç¤ºï¼š  
è¾“å…¥æç¤ºï¼š  
    0)create a function named f to do the following steps   
    1)Import TensorFlow 2.10.0  
    2)Generate input data    
    3)Call the API tf.nn.conv2d(input,filters,strides, padding,data_format='NHWC',dilations=None,name=None)  
ä»£ç ç”Ÿæˆï¼š  
      ```python   
      def f():  
          import tensorflow as tf  
          input_data = tf.random.normal([1, 2, 2, 1])  
          filters = tf.random.normal([2, 2, 1, 1])  
          strides = [1, 1, 1, 1]  
          padding = 'SAME'  
          output = tf.nn.conv2d(input_data, filters, strides, padding, data_format='NHWC', dilations=None, name=None)  
          return output
---
#### ç”¨incoderçªå˜ä»£ç ç§å­åº“ï¼ˆå…·ä½“ä»£ç å®ç°æŸ¥çœ‹example_incoder_usage.pyï¼‰
1. å˜å¼‚ç®—å­ä¸»è¦æœ‰å››ç±»â€”â€”`å‚æ•°`ã€`å‰ç¼€`ã€`åç¼€`å’Œ`æ–¹æ³•`
2. å˜å¼‚ç®—å­çš„é€‰æ‹©  
å°†å¦‚ä½•ä¸ºæ¯ä¸ªç›®æ ‡apié€‰æ‹©æœ€åˆé€‚çš„çªå˜ç®—å­é—®é¢˜è§†ä½œ`Bernoulli bandit problem`ï¼Œå¹¶ä¸”åˆ©ç”¨ç»å…¸çš„`Thompson Sampling (TS) algorithm`æ¥é€‰æ‹©çªå˜ç®—å­ã€‚
3. è‡ªåŠ¨å˜å¼‚æµ‹è¯•ä»£ç   
æ ¹æ®ä¸Šè¿°åˆ©ç”¨codexæ¨¡å‹è‡ªåŠ¨ç”Ÿæˆçš„`ç§å­ä»£ç `ç»“åˆä¸Šæ­¥é€‰æ‹©å‡ºçš„`å˜å¼‚ç®—å­`è¿›è¡Œ`ä»£ç çªå˜`å±•ç¤ºï¼š  
    * ç›®æ ‡apiï¼š`tf.nn.conv2d`  
    - é€‰æ‹©çš„å˜å¼‚ç®—å­ï¼š`æ–¹æ³•`
    * ä»£ç æ©ç›–ï¼š
        ```python
        def f():
          import tensorflow as tf
          input_data = tf.<insert>([1, 2, 2, 1])
          filters = tf.<insert>([2, 2, 1, 1])
          strides = [1, 1, 1, 1]
          padding = 'SAME'
          output = tf.nn.conv2d(input_data, filters, strides, padding, data_format='NHWC', dilations=None, name=None)
          return output
    - ä»£ç çªå˜ï¼š
        ```python 
        def f():
          import tensorflow as tf
          input_data = tf.random_uniform([1, 2, 2, 1])
          filters = tf.random_uniform([2, 2, 1, 1])
          strides = [1, 1, 1, 1]
          padding = 'SAME'
          output = tf.nn.conv2d(input_data, filters, strides, padding, data_format='NHWC', dilations=None, name=None)
          return output

4. è¯„åˆ¤è‡ªåŠ¨åŒ–ç”Ÿæˆçš„æµ‹è¯•ä»£ç   
    * æ•°æ®æµå›¾çš„æ·±åº¦ï¼šè‡ªåŠ¨å˜å¼‚åçš„æµ‹è¯•ä»£ç æ•°æ®æµå›¾æ·±åº¦è¶Šæ·±è¯¥æµ‹è¯•ä»£ç å¾—åˆ†è¶Šé«˜
    - apiæ¥å£çš„æ•°é‡ï¼šè‡ªåŠ¨å˜å¼‚åçš„æµ‹è¯•ä»£ç åŒ…å«çš„ä¸åŒapiæ¥å£æ•°é‡è¶Šå¤šå¾—åˆ†è¶Šé«˜
---
#### ç»“åˆcoderå’Œincoderçš„æ¨¡ç³Šæ£€æµ‹æµç¨‹ï¼ˆå…·ä½“ä»£ç å®ç°æŸ¥çœ‹fuzzing.pyï¼‰
1. ç¡®å®š`ç›®æ ‡api`å’Œ`æ—¶é—´é¢„ç®—`ï¼ˆåœ¨å¤šé•¿æ—¶é—´å†…å¯¹é€‰æ‹©çš„ç›®æ ‡apiè¿›è¡Œä»£ç çªå˜ï¼‰
2. åˆ©ç”¨codexæ¨¡å‹åˆå§‹åŒ–ç”Ÿæˆæ‰€é€‰çš„ç›®æ ‡apiçš„ä»£ç ç§å­åº“
3. åˆå§‹åŒ–æ¯ä¸ªçªå˜ç®—å­çš„å…ˆéªŒæ¦‚ç‡
4. è¿›å…¥æ—¶é—´å¾ªç¯å†…
5. è¯„åˆ¤è‡ªåŠ¨å˜å¼‚ç”Ÿæˆçš„ä»£ç ï¼Œæ ¹æ®å¾—åˆ†é€‰æ‹©å½“å‰çš„ç§å­ä»£ç 
6. é€‰æ‹©å˜å¼‚ç®—å­
7. å¯¹å½“å‰ç§å­ä»£ç è¿›è¡Œçªå˜æ©ç›–
8. åˆ©ç”¨incoderæ¨¡å‹å¡«å……ç”Ÿæˆä¸Šæ­¥ä»£ç æ©ç›–éƒ¨åˆ†
9. é™æ€åˆ†æç”Ÿæˆçš„æ ·æœ¬ä»£ç 
10. æ ¹æ®ç”Ÿæˆçš„æ ·æœ¬ä»£ç æ­£ç¡®å’Œé”™è¯¯ä¸ªæ•°æ›´æ–°å˜å¼‚ç®—å­çš„åéªŒæ¦‚ç‡
11. å¯¹ç”Ÿæˆçš„æ ·æœ¬ä»£ç æ‰“åˆ†
12. å°†å¾—åˆ†é«˜çš„æ­£ç¡®æ ·æœ¬ä»£ç åŠ å…¥åˆ°ç§å­åº“ä¸­
13. é‡å¤ä¸Šè¿°å¾ªç¯
14. åˆ°è¾¾é¢„ç®—æ—¶é—´é€€å‡ºæ—¶é—´å¾ªç¯
15. è·å¾—è¯¥ç›®æ ‡apiæœ€ç»ˆä»£ç çªå˜åç”Ÿæˆçš„æµ‹è¯•ä»£ç åº“
---
    éœ€æ³¨æ„ï¼š
    è¯¥è®ºæ–‡ä¸­æ‰€ç”¨çš„codexæ¨¡å‹æ˜¯ç”±openaiç ”å‘çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œç›®å‰å®˜ç½‘ä¸Šå·²å°†å…¶å¼ƒç”¨ğŸ˜­
    é€‰æ‹©å¯ä»¥å®ç°å’ŒcodexåŒæ ·åŠŸèƒ½çš„text-davinci-003æ¨¡å‹è¿›è¡Œæ›¿ä»£
    å› æ­¤codex.pyä»£ç å®ç°æ‰€ç”¨æ¨¡å‹æ˜¯æ›¿ä»£åçš„text-davinci-003æ¨¡å‹
    code_generate.txtæ˜¯åˆ©ç”¨æ›¿ä»£åçš„text-davinci-003æ¨¡å‹æ ¹æ®æç¤ºè‡ªåŠ¨ç”Ÿæˆçš„å…³äºç›®æ ‡apiçš„æµ‹è¯•ä»£ç 
    å…¨æ–‡æœ€ç»ˆå®ç°å¤ç°çš„ä»£ç æ–‡ä»¶æ˜¯fuzzing.py




